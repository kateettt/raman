{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install peakutils"
      ],
      "metadata": {
        "id": "Nyhj0cQ1DmCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec09088c-6776-4ea5-c51c-eddb4324b835"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peakutils\n",
            "  Downloading PeakUtils-1.3.4-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from peakutils) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from peakutils) (1.11.4)\n",
            "Installing collected packages: peakutils\n",
            "Successfully installed peakutils-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "metadata": {
        "id": "-PQ51CpbdCvh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from peakutils import baseline\n",
        "from sklearn import preprocessing\n",
        "from scipy.signal import savgol_filter\n",
        "from peakutils import indexes\n",
        "from scipy.signal import find_peaks as fp\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "fileal1 = os.listdir('/content/drive/MyDrive/testml/Alanine_1')\n",
        "fileal2 = os.listdir('/content/drive/MyDrive/testml/Alanine_2')\n",
        "fileal3 = os.listdir('/content/drive/MyDrive/testml/Alanine_3')\n",
        "filegl1 = os.listdir('/content/drive/MyDrive/testml/Glutamine_1')\n",
        "filegl2 = os.listdir('/content/drive/MyDrive/testml/Glutamine_2')\n",
        "filegl3 = os.listdir('/content/drive/MyDrive/testml/Glutamine_3')"
      ],
      "metadata": {
        "id": "Eu8nRxLKdDi8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаю датафрейм для усреднённого аланина\n",
        "filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_1/', fileal1[0])\n",
        "temp = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "temp.columns = ['x', 'y']\n",
        "# print(temp)\n",
        "for i in range(1, len(fileal1)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_1/', fileal1[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  for j in range(len(df)):\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] + df.iloc[j, 1]\n",
        "for i in range(len(fileal2)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_2/', fileal2[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  for j in range(len(df)):\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] + df.iloc[j, 1]\n",
        "for i in range(len(fileal3)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_3/', fileal3[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  for j in range(len(df)):\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] + df.iloc[j, 1]\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] / (len(fileal1) + len(fileal2) + len(fileal3))\n",
        "# print(temp)"
      ],
      "metadata": {
        "id": "lKyJ9q2CdGii"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# высчитываю усреднённые пики у аланина, добавляю в сет с частотами пиков\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "names = temp.columns\n",
        "d = scaler.fit_transform(temp)\n",
        "df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "deg = 80\n",
        "bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "wl = 5\n",
        "po = 1\n",
        "df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "t = {'x': temp.x, 'y': df_filt}\n",
        "df_final = pd.DataFrame(t, columns = names)\n",
        "\n",
        "h = 0.1\n",
        "prom = 0.12\n",
        "dist = None\n",
        "p, _ = fp(df_final.y, height = h, prominence = prom, distance = dist)\n",
        "mas = [0]*len(p)\n",
        "for i in range(len(p)):\n",
        "  mas[i] = df_final.iloc[p[i], 0]\n",
        "tn = set(mas)"
      ],
      "metadata": {
        "id": "6DCnIkjqdKWP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаю датафрейм усреднённого глутамина\n",
        "filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_1/', filegl1[0])\n",
        "temp = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "temp.columns = ['x', 'y']\n",
        "for i in range(1, len(filegl1)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_1/', filegl1[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  for j in range(len(df)):\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] + df.iloc[j, 1]\n",
        "for i in range(len(filegl2)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_2/', filegl2[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  for j in range(len(df)):\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] + df.iloc[j, 1]\n",
        "for i in range(len(filegl3)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_3/', filegl3[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  for j in range(len(df)):\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] + df.iloc[j, 1]\n",
        "    temp.at[j, 'y'] = temp.iloc[j, 1] / (len(filegl1) + len(filegl2) + len(filegl3))\n",
        "# print(temp)"
      ],
      "metadata": {
        "id": "6-rM7gJOdQkZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# высчитываю пики у усреднённого глутамина, добавляю частоты пиков в сет\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "names = temp.columns\n",
        "d = scaler.fit_transform(temp)\n",
        "df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "deg = 50\n",
        "bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "wl = 5\n",
        "po = 1\n",
        "df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "t = {'x': temp.x, 'y': df_filt}\n",
        "df_final = pd.DataFrame(t, columns = names)\n",
        "\n",
        "h = 0.1\n",
        "prom = 0.12\n",
        "dist = None\n",
        "p, _ = fp(df_final.y, height = h, prominence = prom, distance = dist)\n",
        "for i in range(len(p)):\n",
        "  tn.add(df_final.iloc[p[i], 0])"
      ],
      "metadata": {
        "id": "bOPxfVd_d9rK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаю пустой главный датафрейм на нужное количество строк (аминокислот) и столбцами с названиями частот пиков у аланина и глутамина и \"y\" (1 -- аланин, 0 -- глутамин)\n",
        "k = len(fileal1) + len(fileal2) + len(fileal3) + len(filegl1) + len(filegl2) + len(filegl3)\n",
        "arr = list(tn)\n",
        "arr.sort()\n",
        "arr = arr[::-1]\n",
        "maindf = pd.DataFrame(0, index = range(k), columns = ['y', *list(arr)])"
      ],
      "metadata": {
        "id": "oGRVPLY2eYNT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# заполняю главный датафрейм, обрабатывая каждый спектр\n",
        "for i in range(len(fileal1)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_1/', fileal1[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "  deg = 80\n",
        "  bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "  wl = 5\n",
        "  po = 1\n",
        "  df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "  t = {'x': df.x, 'y': df_filt}\n",
        "  df_final = pd.DataFrame(t, columns = names)\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  maindf.at[i, 'y'] = 1\n",
        "  for j in range(len(arr)):\n",
        "    maindf.iloc[i, (j+1)] = df_final[df_final['x']==arr[j]].iloc[0, 1]\n",
        "\n",
        "for i in range(len(fileal2)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_2/', fileal2[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "  deg = 80\n",
        "  bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "  wl = 5\n",
        "  po = 1\n",
        "  df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "  t = {'x': df.x, 'y': df_filt}\n",
        "  df_final = pd.DataFrame(t, columns = names)\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  maindf.at[(i+len(fileal1)), 'y'] = 1\n",
        "  for j in range(len(arr)):\n",
        "    maindf.iloc[(i+len(fileal1)), (j+1)] = df_final[df_final['x']==arr[j]].iloc[0, 1]\n",
        "\n",
        "for i in range(len(fileal3)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Alanine_3/', fileal3[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "  deg = 80\n",
        "  bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "  wl = 5\n",
        "  po = 1\n",
        "  df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "  t = {'x': df.x, 'y': df_filt}\n",
        "  df_final = pd.DataFrame(t, columns = names)\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  maindf.at[(i+len(fileal1)+len(fileal2)), 'y'] = 1\n",
        "  for j in range(len(arr)):\n",
        "    maindf.iloc[(i+len(fileal1)+len(fileal2)), (j+1)] = df_final[df_final['x']==arr[j]].iloc[0, 1]\n",
        "\n",
        "for i in range(len(filegl1)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_1/', filegl1[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "  deg = 50\n",
        "  bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "  wl = 5\n",
        "  po = 1\n",
        "  df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "  t = {'x': df.x, 'y': df_filt}\n",
        "  df_final = pd.DataFrame(t, columns = names)\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  maindf.at[(i+len(fileal1)+len(fileal2)+len(fileal3)), 'y'] = 0\n",
        "  for j in range(len(arr)):\n",
        "    maindf.iloc[(i+len(fileal1)+len(fileal2)+len(fileal3)), (j+1)] = df_final[df_final['x']==arr[j]].iloc[0, 1]\n",
        "\n",
        "for i in range(len(filegl2)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_2/', filegl2[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "  deg = 50\n",
        "  bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "  wl = 5\n",
        "  po = 1\n",
        "  df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "  t = {'x': df.x, 'y': df_filt}\n",
        "  df_final = pd.DataFrame(t, columns = names)\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  maindf.at[(i+len(fileal1)+len(fileal2)+len(fileal3)+len(filegl1)), 'y'] = 0\n",
        "  for j in range(len(arr)):\n",
        "    maindf.iloc[(i+len(fileal1)+len(fileal2)+len(fileal3)+len(filegl1)), (j+1)] = df_final[df_final['x']==arr[j]].iloc[0, 1]\n",
        "\n",
        "for i in range(len(filegl3)):\n",
        "  filepath = os.path.join('/content/drive/MyDrive/testml/Glutamine_3/', filegl3[i])\n",
        "  df = pd.read_csv(filepath, delimiter='\\t', header = None)\n",
        "  df.columns = ['x', 'y']\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = df.columns\n",
        "  d = scaler.fit_transform(df)\n",
        "  df_scaler = pd.DataFrame(d, columns = names)\n",
        "\n",
        "  deg = 50\n",
        "  bl = baseline(df_scaler.y, deg = deg)\n",
        "\n",
        "  wl = 5\n",
        "  po = 1\n",
        "  df_filt = savgol_filter(df_scaler.y - bl, window_length = wl, polyorder = po)\n",
        "\n",
        "  t = {'x': df.x, 'y': df_filt}\n",
        "  df_final = pd.DataFrame(t, columns = names)\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  maindf.at[(i+len(fileal1)+len(fileal2)+len(fileal3)+len(filegl1)+len(filegl2)), 'y'] = 0\n",
        "  for j in range(len(arr)):\n",
        "    maindf.iloc[(i+len(fileal1)+len(fileal2)+len(fileal3)+len(filegl1)+len(filegl2)), (j+1)] = df_final[df_final['x']==arr[j]].iloc[0, 1]\n",
        "\n",
        "# print(maindf)"
      ],
      "metadata": {
        "id": "qkoPlI96e8fK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разделяю данные на тренировочные и тестовые\n",
        "x = maindf.iloc[:, 1:].values.tolist()\n",
        "y = maindf['y'].tolist()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.8, shuffle = True, stratify = y, random_state=42)"
      ],
      "metadata": {
        "id": "qTO1aej-fwwc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# классификатор DecisionTreeClassifier()\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "decision_tree.fit(x_train, y_train)\n",
        "\n",
        "predicted = decision_tree.predict(x_test)\n",
        "# print(predicted)\n",
        "# print(y_test)\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] != predicted[i]:\n",
        "    print(predicted[i], i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs5RYs1Ff7GD",
        "outputId": "d3ddb5a3-8e2b-4dc8-9a7a-c5a88a188153"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 186\n",
            "0 240\n",
            "0 406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# классификатор RandomForestClassifier()\n",
        "forest = RandomForestClassifier()\n",
        "\n",
        "forest.fit(x_train, y_train)\n",
        "\n",
        "predicted = forest.predict(x_test)\n",
        "# print(predicted)\n",
        "# print(y_test)\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] != predicted[i]:\n",
        "    print(predicted[i], i)"
      ],
      "metadata": {
        "id": "a8fKUZU7gNEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# значения точности\n",
        "accuracy = accuracy_score(y_test, predicted)\n",
        "print(accuracy)\n",
        "\n",
        "precision = precision_score(y_test, predicted)\n",
        "print(precision)\n",
        "\n",
        "recall = recall_score(y_test, predicted)\n",
        "print(recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyE7qqjvge4p",
        "outputId": "f3ca16a1-7849-4e3d-e828-a5ee0e733e02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9948364888123924\n",
            "1.0\n",
            "0.9896551724137931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# подбор лучших параметров\n",
        "parameter_grid = {\n",
        "    'max_depth' : np.arange(1,20,1),\n",
        "    'min_samples_leaf': np.arange(1,5,1)\n",
        "}\n",
        "\n",
        "grid_searcher = GridSearchCV(estimator=DecisionTreeClassifier(),\n",
        "                             param_grid=parameter_grid,\n",
        "                             cv=25,\n",
        "                             scoring='accuracy',\n",
        "                             n_jobs=-1\n",
        "                            )\n",
        "\n",
        "grid_searcher.fit(x_train, y_train)\n",
        "\n",
        "print(grid_searcher.best_params_)\n",
        "print(grid_searcher.best_score_)\n",
        "\n",
        "grid_searcher = GridSearchCV(estimator=DecisionTreeClassifier(),\n",
        "                             param_grid=parameter_grid,\n",
        "                             cv=25,\n",
        "                             scoring='precision',\n",
        "                             n_jobs=-1\n",
        "                            )\n",
        "\n",
        "grid_searcher.fit(x_train, y_train)\n",
        "\n",
        "print(grid_searcher.best_params_)\n",
        "print(grid_searcher.best_score_)\n",
        "\n",
        "grid_searcher = GridSearchCV(estimator=DecisionTreeClassifier(),\n",
        "                             param_grid=parameter_grid,\n",
        "                             cv=25,\n",
        "                             scoring='recall',\n",
        "                             n_jobs=-1\n",
        "                            )\n",
        "\n",
        "grid_searcher.fit(x_train, y_train)\n",
        "\n",
        "print(grid_searcher.best_params_)\n",
        "print(grid_searcher.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSq80egQgwWN",
        "outputId": "9a2b8477-5883-4947-95da-07d5bcb3809b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 1, 'min_samples_leaf': 1}\n",
            "1.0\n",
            "{'max_depth': 1, 'min_samples_leaf': 1}\n",
            "1.0\n",
            "{'max_depth': 1, 'min_samples_leaf': 1}\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# кросс-валидация\n",
        "cv = KFold(n_splits = 25, shuffle = True)\n",
        "\n",
        "scores = cross_validate(decision_tree, x, y, cv=cv, scoring = {'accuracy':'accuracy'}, n_jobs = -1)\n",
        "print(scores['test_accuracy'])\n",
        "\n",
        "scores = cross_validate(decision_tree, x, y, cv=cv, scoring = {'precision':'precision'}, n_jobs = -1)\n",
        "print(scores['test_precision'])\n",
        "\n",
        "scores = cross_validate(decision_tree, x, y, cv=cv, scoring = {'recall':'recall'}, n_jobs = -1)\n",
        "print(scores['test_recall'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWxc36r0g_ET",
        "outputId": "a6c0a764-d335-4d39-b732-65331e5f689b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         1.         1.         0.96551724 1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.        ]\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.92307692 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.        ]\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94117647 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.        ]\n"
          ]
        }
      ]
    }
  ]
}